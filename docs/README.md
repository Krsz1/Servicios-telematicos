# ğŸ§ª GuÃ­a Completa de Pruebas - Load Balancer

Esta guÃ­a proporciona instrucciones detalladas para ejecutar y analizar pruebas de carga en el sistema de balanceo con **1, 2, 3 y 4 servidores backend**.

---

## ğŸ“‹ Tabla de Contenidos

- [1. Pruebas de Carga con Artillery](#1-pruebas-de-carga-con-artillery)
- [2. Pruebas con 2 Servidores](#2-pruebas-con-2-servidores)
- [3. Pruebas con 3 Servidores](#3-pruebas-con-3-servidores-configuraciÃ³n-por-defecto)
- [4. Pruebas con 4 Servidores](#4-pruebas-con-4-servidores)
- [5. Pruebas con 1 Servidor](#5-pruebas-con-1-servidor-escenario-extremo)
- [6. Ver EstadÃ­sticas del Load Balancer](#6-ver-estadÃ­sticas-del-load-balancer)
- [7. Pruebas Manuales de Balanceo](#7-pruebas-manuales-de-balanceo)
- [8. Limpiar Logs](#8-limpiar-logs)
- [AnÃ¡lisis y ComparaciÃ³n de Resultados](#-anÃ¡lisis-y-comparaciÃ³n-de-resultados)
- [Comando Todo-en-Uno por ConfiguraciÃ³n](#-comando-todo-en-uno-por-configuraciÃ³n)

---

## âš™ï¸ Prerequisitos

Antes de comenzar, asegÃºrate de que:

- âœ… Todas las VMs estÃ©n corriendo: `vagrant status`
- âœ… El Load Balancer estÃ© funcionando: `curl http://localhost:8080`
- âœ… Artillery estÃ© instalado en client: `vagrant ssh client -c "artillery --version"`
- âœ… Scripts de anÃ¡lisis tengan permisos: `chmod +x /vagrant/analysis/*.sh`

---

## 1. Pruebas de Carga con Artillery

El proyecto incluye **3 escenarios de prueba** configurados:

### ğŸ“Š Tipos de Pruebas Disponibles

| Prueba | DescripciÃ³n | DuraciÃ³n | Carga | Total Peticiones |
|--------|-------------|----------|-------|------------------|
| **baseline** | Carga constante | 60s | 50 req/s | ~3,000 |
| **ramp** | Carga incremental | 360s | 10â†’200 req/s | ~37,200 |
| **spike** | Pico de trÃ¡fico | 120s | 50â†’500â†’50 req/s | ~19,500 |

### 1.1 Conectar al Cliente

```bash
vagrant ssh client
cd /vagrant/artillery
```

### 1.2 Ejecutar Pruebas Individuales

#### Baseline: Carga Constante

```bash
artillery run baseline.yml --output /vagrant/reports/baseline.json
```

**ConfiguraciÃ³n:**
- â±ï¸ DuraciÃ³n: 60 segundos
- ğŸ“Š Tasa: 50 peticiones/segundo
- ğŸ¯ Comportamiento esperado: Sistema estable, latencia <50ms, 0% errores

#### Ramp: Carga Incremental

```bash
artillery run ramp.yml --output /vagrant/reports/ramp.json
```

**ConfiguraciÃ³n:**
- **Fase 1:** 120s @ 10 req/s (warmup)
- **Fase 2:** 240s @ 50 req/s (normal)
- **Fase 3:** 240s @ 100 req/s (crecimiento)
- **Fase 4:** 120s @ 200 req/s (alta carga)

#### Spike: Pico de TrÃ¡fico

```bash
artillery run spike.yml --output /vagrant/reports/spike.json
```

**ConfiguraciÃ³n:**
- **Fase 1:** 30s @ 500 req/s (pico extremo)
- **Fase 2:** 90s @ 50 req/s (recuperaciÃ³n)
- âš ï¸ Se esperan errores durante el pico

### 1.3 Generar Reportes HTML

```bash
artillery report /vagrant/reports/baseline.json --output /vagrant/reports/baseline.html
artillery report /vagrant/reports/ramp.json --output /vagrant/reports/ramp.html
artillery report /vagrant/reports/spike.json --output /vagrant/reports/spike.html

exit
```

---

## 2. Pruebas con 2 Servidores

### Paso 1: Detener web3

```bash
vagrant halt web3
```

### Paso 2: Actualizar configuraciÃ³n del LB

```bash
vagrant ssh lb
sudo cp /vagrant/nginx/lb_2servers.conf /etc/nginx/conf.d/lb.conf
sudo nginx -t
sudo systemctl reload nginx
exit
```

### Paso 3: Ejecutar las 3 pruebas

```bash
vagrant ssh client
cd /vagrant/artillery
```

**Ejecutar todas las pruebas:**

```bash
# Baseline
artillery run baseline.yml --output /vagrant/reports/baseline_2servers.json

# Ramp
artillery run ramp.yml --output /vagrant/reports/ramp_2servers.json

# Spike
artillery run spike.yml --output /vagrant/reports/spike_2servers.json
```

### Paso 4: Generar reportes automÃ¡ticos

```bash
chmod +x /vagrant/analysis/generate_report.sh

bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_2servers.json "baseline_2servidores"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_2servers.json "ramp_2servidores"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_2servers.json "spike_2servidores"

exit
```

### Paso 5: Ver estadÃ­sticas del LB

```bash
vagrant ssh lb
sudo bash /vagrant/analysis/stats.sh
exit
```

---

## 3. Pruebas con 3 Servidores (ConfiguraciÃ³n por Defecto)

### Paso 1: Levantar web3 (si estÃ¡ apagado)

```bash
vagrant up web3
```

### Paso 2: Restaurar configuraciÃ³n de 3 servidores

```bash
vagrant ssh lb
sudo cp /vagrant/nginx/lb.conf /etc/nginx/conf.d/lb.conf
sudo nginx -t
sudo systemctl reload nginx
exit
```

### Paso 3: Verificar balanceo Round-Robin

```bash
vagrant ssh client
for i in {1..9}; do 
    printf "PeticiÃ³n %2d: " $i
    curl -s http://192.168.56.10 | grep -o "Servidor web [0-9]"
done
exit
```

**Resultado esperado:**
```
PeticiÃ³n  1: Servidor web 1
PeticiÃ³n  2: Servidor web 2
PeticiÃ³n  3: Servidor web 3
PeticiÃ³n  4: Servidor web 1  â† Vuelve al primero
PeticiÃ³n  5: Servidor web 2
...
```

### Paso 4: Ejecutar las 3 pruebas

```bash
vagrant ssh client
cd /vagrant/artillery

# Ejecutar todas las pruebas
artillery run baseline.yml --output /vagrant/reports/baseline_3servers.json
artillery run ramp.yml --output /vagrant/reports/ramp_3servers.json
artillery run spike.yml --output /vagrant/reports/spike_3servers.json
```

### Paso 5: Generar reportes

```bash
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_3servers.json "baseline_3servidores"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_3servers.json "ramp_3servidores"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_3servers.json "spike_3servidores"

exit
```

---

## 4. Pruebas con 4 Servidores

### ğŸš€ ConfiguraciÃ³n con 4 Servidores Backend

Esta secciÃ³n agrega un **cuarto servidor** para evaluar el escalamiento horizontal.

### Paso 1: Crear y arrancar web4

```bash
vagrant up web4
```

**QuÃ© hace:**
- Crea VM Ubuntu con IP: 192.168.56.14
- Instala y configura NGINX
- Tiempo estimado: 3-5 minutos

### Paso 2: Verificar que web4 estÃ© funcionando

```bash
vagrant status web4
```

**Resultado esperado:**
```
web4                      running (virtualbox)
```

### Paso 3: Actualizar Load Balancer a 4 servidores

```bash
vagrant ssh lb
sudo cp /vagrant/nginx/lb_4servers.conf /etc/nginx/conf.d/lb.conf
sudo nginx -t
sudo systemctl reload nginx
exit
```

**Pool de backends actualizado:**
- 192.168.56.11 (web1)
- 192.168.56.12 (web2)
- 192.168.56.13 (web3)
- 192.168.56.14 (web4) â† **NUEVO**

### Paso 4: Verificar balanceo con 4 servidores

```bash
vagrant ssh client
for i in {1..12}; do 
    printf "PeticiÃ³n %2d: " $i
    curl -s http://192.168.56.10 | grep -o "Servidor web [0-9]"
done
exit
```

**Resultado esperado:**
```
PeticiÃ³n  1: Servidor web 1
PeticiÃ³n  2: Servidor web 2
PeticiÃ³n  3: Servidor web 3
PeticiÃ³n  4: Servidor web 4  â† El cuarto servidor
PeticiÃ³n  5: Servidor web 1  â† Vuelve al primero (round-robin)
...
```

### Paso 5: Ejecutar prueba BASELINE

```bash
vagrant ssh client
cd /vagrant/artillery
artillery run baseline.yml --output /vagrant/reports/baseline_4servers.json
```

â±ï¸ **Tiempo estimado:** 60 segundos

### Paso 6: Generar reporte de BASELINE

```bash
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_4servers.json "baseline_4servidores"
```

ğŸ“ **Archivo generado:** `reports/baseline_4servers_resumen.md`

### Paso 7: Ejecutar prueba RAMP

```bash
artillery run ramp.yml --output /vagrant/reports/ramp_4servers.json
```

â±ï¸ **Tiempo estimado:** 5-6 minutos

### Paso 8: Generar reporte de RAMP

```bash
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_4servers.json "ramp_4servidores"
```

### Paso 9: Ejecutar prueba SPIKE

```bash
artillery run spike.yml --output /vagrant/reports/spike_4servers.json
```

â±ï¸ **Tiempo estimado:** 90 segundos  
âš ï¸ **Nota:** Se esperan menos errores que con 2 o 3 servidores

### Paso 10: Generar reporte de SPIKE

```bash
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_4servers.json "spike_4servidores"

exit
```

### Paso 11: Regenerar anÃ¡lisis comparativo completo

```bash
vagrant ssh client
bash /vagrant/analysis/generate_comparative_report.sh
exit
```

ğŸ“Š **Archivo actualizado:** `reports/ANALISIS_COMPARATIVO.md`

**QuÃ© hace:**
- Compara rendimiento: 1 vs 2 vs 3 vs 4 servidores
- Compara pruebas: baseline vs ramp vs spike
- Genera conclusiones automÃ¡ticas
- Identifica configuraciÃ³n Ã³ptima

### Paso 12 (OPCIONAL): Restaurar a 3 servidores

```bash
# Detener web4
vagrant halt web4

# Restaurar configuraciÃ³n del LB
vagrant ssh lb
sudo cp /vagrant/nginx/lb.conf /etc/nginx/conf.d/lb.conf
sudo systemctl reload nginx
exit
```

---

## 5. Pruebas con 1 Servidor (Escenario Extremo)

> **âš ï¸ Advertencia:** Esta prueba muestra los lÃ­mites de un solo servidor bajo carga

### Paso 1: Detener web2 y web3

```bash
vagrant halt web2
vagrant halt web3
```

### Paso 2: Actualizar configuraciÃ³n a 1 servidor

```bash
vagrant ssh lb
sudo cp /vagrant/nginx/lb_1server.conf /etc/nginx/conf.d/lb.conf
sudo nginx -t
sudo systemctl reload nginx
exit
```

### Paso 3: Ejecutar las 3 pruebas

```bash
vagrant ssh client
cd /vagrant/artillery

# Baseline
artillery run baseline.yml --output /vagrant/reports/baseline_1server.json

# Ramp (se esperan errores)
artillery run ramp.yml --output /vagrant/reports/ramp_1server.json

# Spike (probablemente falle mucho)
artillery run spike.yml --output /vagrant/reports/spike_1server.json
```

### Paso 4: Generar reportes

```bash
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_1server.json "baseline_1servidor"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_1server.json "ramp_1servidor"
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_1server.json "spike_1servidor"

exit
```

### Paso 5: Restaurar configuraciÃ³n normal

```bash
# Levantar todos los servidores
vagrant up web2
vagrant up web3

# Restaurar configuraciÃ³n del LB
vagrant ssh lb
sudo cp /vagrant/nginx/lb.conf /etc/nginx/conf.d/lb.conf
sudo nginx -t
sudo systemctl reload nginx
exit

# Verificar que funcione
vagrant ssh client
curl http://192.168.56.10
exit
```

---

## 6. Ver EstadÃ­sticas del Load Balancer

### MÃ©todo 1: nginx_status (tiempo real)

```powershell
# Desde PowerShell en host
curl http://localhost:8080/nginx_status
```

O abrir en navegador: [http://localhost:8080/nginx_status](http://localhost:8080/nginx_status)

**InformaciÃ³n mostrada:**
```
Active connections: 1 
server accepts handled requests
 1234 1234 5678 
Reading: 0 Writing: 1 Waiting: 0
```

### MÃ©todo 2: Script de anÃ¡lisis completo

```bash
vagrant ssh lb
sudo bash /vagrant/analysis/stats.sh
exit
```

**El script muestra:**
- Total de peticiones procesadas
- DistribuciÃ³n de carga entre servidores
- CÃ³digos de respuesta HTTP
- Tasa de errores
- Tiempos de respuesta

### MÃ©todo 3: Comandos individuales

```bash
vagrant ssh lb
```

#### Total de peticiones

```bash
sudo cat /var/log/nginx/lb_access.log | wc -l
```

#### DistribuciÃ³n por servidor

```bash
sudo cat /var/log/nginx/lb_access.log | grep -oP '\d+\.\d+\.\d+\.\d+:\d+' | sort | uniq -c
```

#### CÃ³digos de estado HTTP

```bash
sudo cat /var/log/nginx/lb_access.log | awk '{print $9}' | sort | uniq -c
```

#### Tasa de errores

```bash
total=$(sudo cat /var/log/nginx/lb_access.log | wc -l)
errores=$(sudo cat /var/log/nginx/lb_access.log | awk '{print $9}' | grep '^5' | wc -l)
echo "Tasa de error: $(echo "scale=2; $errores * 100 / $total" | bc)%"
```

#### Ver logs en tiempo real

```bash
sudo tail -f /var/log/nginx/lb_access.log
```

**Formato del log:**
```
192.168.56.50 - - [11/Nov/2025:10:30:45 +0000] "GET / HTTP/1.1" 200 186 "-" "Artillery" "192.168.56.11:80" 0.002
```

Incluye:
- IP del cliente
- Timestamp
- PeticiÃ³n HTTP
- Status code
- **Servidor backend que atendiÃ³** (`192.168.56.11:80`)
- Tiempo de respuesta (0.002s)

```bash
exit
```

---

## 7. Pruebas Manuales de Balanceo

### Desde PowerShell (Windows)

```powershell
# Hacer 10 peticiones y ver quÃ© servidor responde
for ($i=1; $i -le 10; $i++) { 
    curl http://localhost:8080 | Select-String "Servidor" 
}
```

### Desde el cliente (Linux)

```bash
vagrant ssh client
for i in {1..10}; do 
    curl -s http://192.168.56.10 | grep "Servidor"
done
exit
```

### Prueba de concurrencia con Apache Bench

```bash
vagrant ssh client

# Prueba simple: 1000 peticiones, 10 concurrentes
ab -n 1000 -c 10 http://192.168.56.10/

# Prueba intensiva: 10000 peticiones, 100 concurrentes
ab -n 10000 -c 100 http://192.168.56.10/

exit
```

---

## 8. Limpiar Logs

```bash
vagrant ssh lb
sudo truncate -s 0 /var/log/nginx/lb_access.log
sudo truncate -s 0 /var/log/nginx/lb_error.log
sudo systemctl reload nginx
exit
```

### Hacer backup antes de limpiar

```bash
vagrant ssh lb
sudo cp /var/log/nginx/lb_access.log /vagrant/reports/backup_$(date +%Y%m%d_%H%M%S).log
sudo truncate -s 0 /var/log/nginx/lb_access.log
sudo systemctl reload nginx
exit
```

---

## ğŸ“Š AnÃ¡lisis y ComparaciÃ³n de Resultados

DespuÃ©s de ejecutar todas las pruebas, tendrÃ¡s hasta **12 reportes** para comparar:

### ğŸ“ Estructura de Reportes Generados

```
reports/
â”œâ”€â”€ baseline_1server.json               # Datos raw
â”œâ”€â”€ baseline_1server_resumen.md         # AnÃ¡lisis
â”œâ”€â”€ baseline_2servers.json
â”œâ”€â”€ baseline_2servers_resumen.md
â”œâ”€â”€ baseline_3servers.json
â”œâ”€â”€ baseline_3servers_resumen.md
â”œâ”€â”€ baseline_4servers.json
â”œâ”€â”€ baseline_4servers_resumen.md
â”œâ”€â”€ ramp_1server.json
â”œâ”€â”€ ramp_1server_resumen.md
â”œâ”€â”€ ramp_2servers.json
â”œâ”€â”€ ramp_2servers_resumen.md
â”œâ”€â”€ ramp_3servers.json
â”œâ”€â”€ ramp_3servers_resumen.md
â”œâ”€â”€ ramp_4servers.json
â”œâ”€â”€ ramp_4servers_resumen.md
â”œâ”€â”€ spike_1server.json
â”œâ”€â”€ spike_1server_resumen.md
â”œâ”€â”€ spike_2servers.json
â”œâ”€â”€ spike_2servers_resumen.md
â”œâ”€â”€ spike_3servers.json
â”œâ”€â”€ spike_3servers_resumen.md
â”œâ”€â”€ spike_4servers.json
â”œâ”€â”€ spike_4servers_resumen.md
â””â”€â”€ ANALISIS_COMPARATIVO.md             # AnÃ¡lisis completo comparativo
```

---

### ğŸ” Preguntas Clave para el AnÃ¡lisis

1. âœ… **Â¿CÃ³mo cambia el rendimiento con diferentes cargas?**
2. âœ… **Â¿QuÃ© pasa cuando reduces/aumentas el nÃºmero de servidores?**
3. âœ… **Â¿La distribuciÃ³n de carga es equitativa?**
4. âœ… **Â¿CuÃ¡l es la tasa de errores bajo carga alta?**
5. âœ… **Â¿CuÃ¡nto tiempo de respuesta promedio hay?**
6. âœ… **Â¿CÃ³mo afecta el nÃºmero de servidores backend al rendimiento del sistema?**
7. âœ… **Â¿A partir de quÃ© carga un solo servidor se satura?**
8. âœ… **Â¿El balanceador distribuye correctamente entre 2, 3 y 4 servidores?**
9. âœ… **Â¿Duplicar servidores duplica la capacidad?**
10. âœ… **Â¿CuÃ¡l es el punto Ã³ptimo de escalamiento?**

---

## ğŸ“ˆ MÃ©tricas Clave a Comparar

| MÃ©trica | DescripciÃ³n | QuÃ© Buscar |
|---------|-------------|------------|
| **Tiempos de respuesta** | mean, p95, p99 | CÃ³mo disminuyen con mÃ¡s servidores |
| **Tasa de Ã©xito** | Porcentaje de requests exitosos | Mejora con mÃ¡s backends |
| **Tasa de errores** | Porcentaje de requests fallidos | Disminuye con mÃ¡s servidores |
| **Throughput** | Peticiones por segundo | Capacidad mÃ¡xima de cada configuraciÃ³n |
| **Capacidad de picos** | Respuesta ante spike test | Resistencia con 1, 2, 3 y 4 servidores |
| **DistribuciÃ³n** | Equilibrio entre backends | Debe ser equitativa (~25% con 4 servers) |

---

## ğŸ¯ Valores Ã“ptimos Esperados

| MÃ©trica | Valor Ã“ptimo | 1 Servidor | 2 Servidores | 3 Servidores | 4 Servidores |
|---------|--------------|------------|--------------|--------------|--------------|
| **Latencia P95** | < 100ms | âš ï¸ Alta (>200ms) | âš ï¸ Media (~100ms) | âœ… Baja (<100ms) | âœ… Muy Baja (<50ms) |
| **Latencia P99** | < 200ms | âŒ Muy Alta | âš ï¸ Media-Alta | âœ… Aceptable | âœ… Baja |
| **Tasa de Error (Baseline)** | 0% | âœ… 0% | âœ… 0% | âœ… 0% | âœ… 0% |
| **Tasa de Error (Spike)** | < 10% | âŒ >50% | âŒ 20-40% | âš ï¸ 5-20% | âœ… <10% |
| **RPS MÃ¡ximo** | Variable | ~30-50 | ~80-100 | ~120-150 | ~150-200 |
| **DistribuciÃ³n** | Equitativa | N/A | ~50% c/u | ~33% c/u | ~25% c/u |

---

## ğŸ” InterpretaciÃ³n de Resultados por Escenario

### Baseline (50 req/s) - Carga Constante

| ConfiguraciÃ³n | Comportamiento Esperado |
|---------------|------------------------|
| **1 Servidor** | âš ï¸ En el lÃ­mite de capacidad, latencia media-alta |
| **2 Servidores** | âœ… Estable, distribuciÃ³n 50/50 |
| **3 Servidores** | âœ… Ã“ptimo, distribuciÃ³n 33/33/33, latencia mÃ­nima |
| **4 Servidores** | âœ… Excelente, distribuciÃ³n 25/25/25/25, latencia muy baja |

### Ramp (10â†’200 req/s) - Carga Incremental

| ConfiguraciÃ³n | Comportamiento Esperado |
|---------------|------------------------|
| **1 Servidor** | âŒ SaturaciÃ³n >50 req/s, muchos errores en fases 3 y 4 |
| **2 Servidores** | âš ï¸ DegradaciÃ³n >100 req/s, errores en fase 4 |
| **3 Servidores** | âœ… Estable hasta ~150 req/s, degradaciÃ³n gradual en fase 4 |
| **4 Servidores** | âœ… Estable hasta ~180 req/s, degradaciÃ³n mÃ­nima en fase 4 |

### Spike (500 req/s) - Pico de TrÃ¡fico Extremo

| ConfiguraciÃ³n | Comportamiento Esperado |
|---------------|------------------------|
| **1 Servidor** | âŒ Colapso total, >50% errores, tiempos de respuesta muy altos |
| **2 Servidores** | âŒ 20-40% errores durante pico, recuperaciÃ³n lenta |
| **3 Servidores** | âš ï¸ 5-20% errores durante pico, recuperaciÃ³n moderada |
| **4 Servidores** | âœ… <10% errores durante pico, recuperaciÃ³n rÃ¡pida |

---

## âš¡ Comando Todo-en-Uno por ConfiguraciÃ³n

Si quieres ejecutar todo automÃ¡ticamente:

### Con 2 Servidores (~8 minutos)

```bash
vagrant halt web3 && \
vagrant ssh lb -c "sudo cp /vagrant/nginx/lb_2servers.conf /etc/nginx/conf.d/lb.conf && sudo nginx -t && sudo systemctl reload nginx" && \
vagrant ssh client -c "cd /vagrant/artillery && \
artillery run baseline.yml -o /vagrant/reports/baseline_2servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_2servers.json baseline_2servidores && \
artillery run ramp.yml -o /vagrant/reports/ramp_2servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_2servers.json ramp_2servidores && \
artillery run spike.yml -o /vagrant/reports/spike_2servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_2servers.json spike_2servidores"
```

### Con 3 Servidores (~8 minutos)

```bash
vagrant up web3 && \
vagrant ssh lb -c "sudo cp /vagrant/nginx/lb.conf /etc/nginx/conf.d/lb.conf && sudo nginx -t && sudo systemctl reload nginx" && \
vagrant ssh client -c "cd /vagrant/artillery && \
artillery run baseline.yml -o /vagrant/reports/baseline_3servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_3servers.json baseline_3servidores && \
artillery run ramp.yml -o /vagrant/reports/ramp_3servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_3servers.json ramp_3servidores && \
artillery run spike.yml -o /vagrant/reports/spike_3servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_3servers.json spike_3servidores"
```

### Con 4 Servidores (~15 minutos - incluye creaciÃ³n de web4)

```bash
vagrant up web4 && \
vagrant ssh lb -c "sudo cp /vagrant/nginx/lb_4servers.conf /etc/nginx/conf.d/lb.conf && sudo nginx -t && sudo systemctl reload nginx" && \
vagrant ssh client -c "cd /vagrant/artillery && \
artillery run baseline.yml -o /vagrant/reports/baseline_4servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/baseline_4servers.json baseline_4servidores && \
artillery run ramp.yml -o /vagrant/reports/ramp_4servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/ramp_4servers.json ramp_4servidores && \
artillery run spike.yml -o /vagrant/reports/spike_4servers.json && \
bash /vagrant/analysis/generate_report.sh /vagrant/reports/spike_4servers.json spike_4servidores && \
bash /vagrant/analysis/generate_comparative_report.sh"
```

---

## ğŸ› ï¸ Troubleshooting

### Las pruebas fallan con errores de conexiÃ³n

```bash
# Verificar que el Load Balancer estÃ© funcionando
vagrant ssh lb -c "sudo systemctl status nginx"
vagrant ssh lb -c "sudo nginx -t"

# Verificar conectividad desde el cliente
vagrant ssh client -c "ping -c 3 192.168.56.10"
vagrant ssh client -c "curl -v http://192.168.56.10"
```

### web4 no arranca correctamente

```bash
# Destruir y recrear web4
vagrant destroy web4 -f
vagrant up web4

# Verificar logs de provisioning
vagrant up web4 --provision
```

### Los reportes no se generan

```bash
# Verificar permisos de los scripts
vagrant ssh client -c "ls -la /vagrant/analysis/*.sh"
vagrant ssh client -c "chmod +x /vagrant/analysis/*.sh"

# Verificar que exista el archivo JSON
vagrant ssh client -c "ls -lh /vagrant/reports/*.json"
```

### Artillery reporta muchos timeouts

```bash
# OpciÃ³n 1: Reducir carga en los archivos YAML
# Edita artillery/*.yml y reduce arrivalRate

# OpciÃ³n 2: Aumentar timeouts en NGINX
vagrant ssh lb
sudo nano /etc/nginx/conf.d/lb.conf
# Cambiar: proxy_connect_timeout, proxy_read_timeout, proxy_send_timeout
sudo nginx -t
sudo systemctl reload nginx
exit
```

### Ver logs de errores del Load Balancer

```bash
vagrant ssh lb -c "sudo tail -n 50 /var/log/nginx/lb_error.log"
```

---

## ğŸ“š Archivos de ConfiguraciÃ³n del Proyecto

### Configuraciones NGINX disponibles

| Archivo | Servidores | Upstream Pool |
|---------|------------|---------------|
| `nginx/lb_1server.conf` | 1 | 192.168.56.11 |
| `nginx/lb_2servers.conf` | 2 | .11, .12 |
| `nginx/lb.conf` | 3 | .11, .12, .13 |
| `nginx/lb_4servers.conf` | 4 | .11, .12, .13, .14 |

### Scripts de anÃ¡lisis

| Script | FunciÃ³n |
|--------|---------|
| `analysis/generate_report.sh` | Genera resumen de un reporte individual |
| `analysis/generate_comparative_report.sh` | Genera anÃ¡lisis comparativo de todos los reportes |
| `analysis/stats.sh` | Muestra estadÃ­sticas en tiempo real del LB |

---

## âœ… Checklist de Completitud

Marca cuando completes cada configuraciÃ³n:

- [ ] **2 Servidores**
  - [ ] Baseline ejecutado y reporte generado
  - [ ] Ramp ejecutado y reporte generado
  - [ ] Spike ejecutado y reporte generado

- [ ] **3 Servidores**
  - [ ] Baseline ejecutado y reporte generado
  - [ ] Ramp ejecutado y reporte generado
  - [ ] Spike ejecutado y reporte generado

- [ ] **4 Servidores**
  - [ ] web4 creado y funcionando
  - [ ] Baseline ejecutado y reporte generado
  - [ ] Ramp ejecutado y reporte generado
  - [ ] Spike ejecutado y reporte generado

- [ ] **1 Servidor (Opcional)**
  - [ ] Baseline ejecutado y reporte generado
  - [ ] Ramp ejecutado y reporte generado
  - [ ] Spike ejecutado y reporte generado

- [ ] **AnÃ¡lisis Final**
  - [ ] AnÃ¡lisis comparativo generado
  - [ ] Todos los archivos `.md` revisados
  - [ ] Conclusiones documentadas

---

## ğŸ† Conclusiones Esperadas

Al finalizar todas las pruebas, podrÃ¡s demostrar:

### 1. Escalabilidad Horizontal Funcional
- El sistema escala linealmente con mÃ¡s servidores
- Round-robin distribuye carga equitativamente (25% con 4 servers)
- Cada servidor adicional mejora la capacidad total

### 2. Mejora en Resistencia a Picos
- Con 4 servidores: mayor capacidad de absorber trÃ¡fico extremo
- Menor tasa de errores en pruebas de spike
- RecuperaciÃ³n mÃ¡s rÃ¡pida despuÃ©s de picos

### 3. Trade-off Recursos vs Rendimiento
- Determinar si 4 servidores justifican el costo adicional
- Identificar punto Ã³ptimo de escalamiento para tu caso de uso
- Rendimientos decrecientes al agregar mÃ¡s servidores

### 4. Comportamiento Bajo Diferentes Cargas
- **Carga constante:** Rendimiento excelente con cualquier configuraciÃ³n >1 servidor
- **Carga incremental:** AdaptaciÃ³n efectiva, degradaciÃ³n gradual predecible
- **Picos extremos:** DegradaciÃ³n controlada, sin caÃ­das catastrÃ³ficas

---

**Fecha de creaciÃ³n:** 11 de noviembre de 2025  
**Ãšltima actualizaciÃ³n:** 11 de noviembre de 2025  
**Autor:** Krsz1  
**VersiÃ³n:** 3.0
